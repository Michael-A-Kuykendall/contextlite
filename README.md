# ContextLite

> **RAG Systems Were a Mistake** - Replace slow, approximate vector databases with mathematically optimal context selection.

âš¡ **0.3ms** response time (vs 30-50ms for vector DBs) | ğŸ¯ **Provably optimal** results via SMT solving | ğŸ’° **$0** ongoing costs (vs $300-500/month for cloud vector DBs) | ğŸ”’ **100% local** - your data never leaves your machine

ContextLite is a production-ready context assembly engine with **enterprise-grade workspace management** and SMT-powered optimization. Perfect for AI applications that demand speed, accuracy, and cost-effectiveness.

## ğŸš€ **Download Now**

**[â¬‡ï¸ Get ContextLite - All Platforms](https://huggingface.co/spaces/MikeKuykendall/contextlite-download)**

### Package Managers
```bash
# npm (Node.js)
npm install -g contextlite

# PyPI (Python)  
pip install contextlite

# Chocolatey (Windows)
choco install contextlite
```

## ğŸ†• **Why ContextLite Beats Vector Databases**

âœ¨ **SMT-Powered Optimization**: Mathematical precision instead of probabilistic approximations

ğŸ“š **[Documentation](./docs/)** | ğŸ˜ï¸ **[Management Guide](./docs/CLUSTERING_GUIDE.md)** | ğŸ“¡ **[API Reference](./docs/API_REFERENCE.md)**

| Feature | ContextLite | Vector DBs |
|---------|-------------|------------|
| **Response Time** | âš¡ 0.3ms | ğŸŒ 30-50ms |
| **Accuracy** | ğŸ¯ Mathematically optimal | ğŸ“Š Approximate similarity |
| **Monthly Costs** | ğŸ’° $0 (local) | ğŸ’¸ $300-500+ (cloud) |
| **Data Privacy** | ğŸ”’ 100% local | â˜ï¸ Uploaded to cloud |
| **Setup Time** | âš¡ 30 seconds | ğŸ• Hours/days |

## ğŸ¢ **Enterprise Workspace Management**

Manage multiple AI projects with professional-grade isolation and resource management:

```bash
# Enable workspace management in your config
workspace:
  enabled: true
  isolation: true
  resource_limits:
    "mission-architect":
      max_concurrent_requests: 10
      max_memory_mb: 512
      priority: 8

# Use workspace-specific requests
curl -H "X-Workspace-ID: mission-architect" \
     -X POST http://localhost:8080/api/v1/assemble \
     -d '{"query": "AI enforcement patterns"}'
```

**Key Benefits:**
- ğŸ˜ï¸ **Workspace Isolation**: Complete separation of projects and resources
- âš–ï¸ **Resource Management**: Per-workspace limits and priority settings  
- ğŸ¯ **Smart Routing**: Intelligent request routing and session management
- ğŸ“Š **Usage Analytics**: Detailed monitoring and access pattern detection
- ğŸ”„ **Load Balancing**: Distribute requests across multiple instances

## ğŸš€ Quick Start

```bash
# Build main contextlite binary
make build

# Build SOTA evaluation tool
make build-sota

# Build both binaries
make build-all-local

# Or with custom config
./build/contextlite -config configs/custom.yaml

# Run SOTA evaluation
./build/sota-eval

# Development mode with hot reload
make dev
```

The server starts on `http://localhost:8080` by default.

## ğŸ”„ Automatic Port Management

ContextLite now supports **automatic port discovery** for applications that need to connect to running instances without hardcoded port numbers:

```go
// No more port configuration issues!
client := NewAutoDiscoveryClient()
if err := client.AutoDiscover(); err != nil {
    log.Fatal("No ContextLite instances found")
}

// Automatically connects to healthy instance
result, err := client.Query("your query here", 10)
```

**Key Benefits:**
- âœ… **Zero Configuration**: Automatically discovers running instances
- âœ… **Port Conflict Resolution**: Works with multiple concurrent instances  
- âœ… **Automatic Failover**: Switches between healthy instances seamlessly
- âœ… **Development Friendly**: No more "port already in use" errors
- âœ… **Production Ready**: Built-in health monitoring and redundancy

**Example Usage:**
```bash
# Start multiple instances on different ports
./contextlite --config configs/workspace1.yaml &  # Starts on 8080
./contextlite --config configs/workspace2.yaml &  # Auto-finds 8081
./contextlite --config configs/workspace3.yaml &  # Auto-finds 8082

# Your application automatically discovers and connects to all instances
go run examples/automatic_port_management.go
```

See [`examples/automatic_port_management.go`](examples/automatic_port_management.go) for a complete integration example.

## âœ¨ Key Features

- **Advanced Document Selection**: Uses sophisticated algorithms for optimal document selection
- **Multi-dimensional Scoring**: Advanced relevance analysis with intelligent optimization
- **Workspace Management**: Multi-project support with resource isolation and routing
- **Adaptive Learning**: Smart weights that learn from your usage patterns  
- **Multi-Level Caching**: Advanced caching system with intelligent invalidation
- **Zero Dependencies**: Pure Go with embedded SQLite, no external services required
- **High Performance**: Fast response times with efficient processing
- **Local Privacy**: All data stays on your machine, no cloud dependencies

## ğŸ“– Documentation

- **[Documentation](./docs/)** - Architecture guides and API reference
- **[Clustering Guide](./docs/CLUSTERING_GUIDE.md)** - Multi-project and workspace management
- **[Contributing Guide](CONTRIBUTING.md)** - Development setup and guidelines  
- **[License](LICENSE)** - MIT License terms

## ğŸ—ï¸ Repository Structure

```
contextlite/
â”œâ”€â”€ cmd/                       # Executable applications
â”‚   â”œâ”€â”€ contextlite/           # HTTP sidecar server
â”‚   â””â”€â”€ sota-eval/             # SOTA comparison CLI tool
â”œâ”€â”€ internal/                  # Private implementation
â”‚   â”œâ”€â”€ optimization/          # Advanced optimization engine
â”‚   â”œâ”€â”€ storage/               # SQLite + FTS5 storage layer
â”‚   â”œâ”€â”€ features/              # Multi-dimensional feature extraction & scoring
â”‚   â”œâ”€â”€ pipeline/              # Main assembly pipeline
â”‚   â”œâ”€â”€ cache/                 # Multi-level caching system
â”‚   â”œâ”€â”€ api/                   # HTTP API handlers
â”‚   â””â”€â”€ evaluation/            # Performance evaluation framework
â”œâ”€â”€ pkg/                       # Public API packages
â”‚   â”œâ”€â”€ types/                 # Core data structures
â”‚   â”œâ”€â”€ config/                # Configuration management
â”‚   â””â”€â”€ tokens/                # Token estimation utilities
â”œâ”€â”€ docs/                      # Technical documentation
â”œâ”€â”€ archive/                   # Historical development artifacts
â”œâ”€â”€ test/                      # Integration tests
â”œâ”€â”€ configs/                   # Default configuration files
â””â”€â”€ migrations/                # Database schema migrations
```

## ğŸ”§ Configuration

See `configs/default.yaml` for full configuration options:

```yaml
# Core optimization settings
optimization:
  timeout_ms: 250              # Response timeout
  precision: 0.05              # Precision threshold
  style: "weighted-sum"        # Optimization approach

# Feature weights (adaptive per workspace)
weights:
  # Weights are automatically tuned based on usage patterns
  # See documentation for configuration options
```

## ğŸ˜ï¸ Workspace Management

ContextLite supports workspace management for managing multiple projects:

```yaml
# Enable workspace management in configs/workspace.yaml
workspace:
  enabled: true
  node_id: "contextlite-node-1"
  
  routing:
    workspace_isolation: true
    session_management: true
    rules:
      "mission-architect":
        preferred_nodes: ["node-1"]
        resource_tier: "high"
        
  resource_limits:
    "mission-architect":
      max_concurrent_requests: 10
      max_tokens_per_minute: 50000
      max_memory_mb: 512
```

**Workspace-aware requests:**
```bash
curl -H "X-Workspace-ID: mission-architect" \
     -X POST http://localhost:8080/api/v1/assemble \
     -d '{"query": "AI enforcement patterns"}'
```

See the [Management Guide](./docs/CLUSTERING_GUIDE.md) for complete setup instructions.

## ğŸ“¡ HTTP API

### Context Assembly
```bash
curl -X POST http://localhost:8080/api/v1/context/assemble \
  -H "Content-Type: application/json" \
  -d '{
    "query": "How does user authentication work?",
    "max_tokens": 4000,
    "max_documents": 10,
    "use_optimization": true,
    "workspace_path": "/path/to/project"
  }'
```

### Document Management
```bash
# Add document
curl -X POST http://localhost:8080/api/v1/documents \
  -H "Content-Type: application/json" \
  -d '{
    "content": "...",
    "path": "src/auth.go",
    "language": "go"
  }'

# Search documents
curl "http://localhost:8080/api/v1/documents/search?q=authentication&limit=20"
```

### Weight Management
```bash
# Get workspace weights
curl "http://localhost:8080/api/v1/weights?workspace=/path/to/project"

# Update weights based on feedback
curl -X POST http://localhost:8080/api/v1/weights/update \
  -H "Content-Type: application/json" \
  -d '{
    "workspace_path": "/path/to/project",
    "accepted_docs": ["doc1", "doc2"],
    "rejected_docs": ["doc3"]
  }'
```

## ğŸ“ˆ Development Status

### âœ… Completed Features
- **Advanced Optimization**: Sophisticated solver integration with multiple strategies
- **7D Feature System**: Complete implementation of all feature dimensions
- **Evaluation Framework**: Comprehensive evaluation harness with Recall@k, nDCG@k, MAP, MRR
- **Multi-level Caching**: Advanced caching system with intelligent invalidation
- **HTTP API**: Complete REST API for context assembly and document management
- **Configuration System**: Flexible YAML-based configuration with workspace-specific weights

### ğŸ“‹ Documentation
- **[Technical Documentation](docs/)** - Architecture, testing, and deployment guides
- **[Contributing Guide](CONTRIBUTING.md)** - Development setup and guidelines  
- **[Development Context](CLAUDE.md)** - AI assistant setup for contributors

## ğŸ§® Advanced Optimization

ContextLite uses sophisticated mathematical optimization for document selection:

- **Weighted Optimization**: Balances multiple relevance factors
- **Priority-based Selection**: Configurable ranking strategies  
- **Budget Management**: Respects token budgets and document limits

See documentation for configuration options.

## ğŸ“Š SOTA Evaluation

ContextLite includes a comprehensive evaluation framework comparing against state-of-the-art retrieval systems:

```bash
# Run full SOTA comparison
./build/sota-eval

# With custom parameters
./build/sota-eval -queries 1000 -docs 100 -verbose
```

**Evaluation Metrics:**
- **Recall@k**: Fraction of relevant documents retrieved in top-k results
- **nDCG@k**: Normalized Discounted Cumulative Gain (position-aware relevance)
- **MAP**: Mean Average Precision across all queries
- **MRR**: Mean Reciprocal Rank of first relevant document

**Baseline Comparisons:**
- BM25 (Elasticsearch/Lucene standard)
- TF-IDF with cosine similarity
- Hybrid semantic + lexical retrieval
- Random baseline for statistical significance

See [`docs/GOLDEN_RECORD_STEP5.md`](docs/GOLDEN_RECORD_STEP5.md) for current evaluation status and identified areas for improvement.

## ğŸƒâ€â™‚ï¸ Performance

Benchmarked on NVMe SSD, 100k documents, K=200 candidates:

| Operation | p50 | p95 | p99 |
|-----------|-----|-----|-----|
| Cached Query | 15ms | 30ms | 45ms |
| Cold Query | 180ms | 350ms | 500ms |
| Optimization | 50ms | 150ms | 250ms |
| Feature Extract | 25ms | 80ms | 120ms |

## ğŸ“Š Development

```bash
# Install dependencies
make deps

# Build main binary
make build

# Build SOTA evaluation tool
make build-sota

# Build both binaries locally
make build-all-local

# Build for all platforms
make build-all

# Run tests
make test

# Run with coverage
make coverage

# Run benchmarks  
make bench

# Code quality checks
make check

# Development with hot reload
make dev

# Clean build artifacts
make clean
```

## ğŸ³ Docker

```bash
# Build image
make docker-build

# Run container
make docker-run
```

## ğŸ“ˆ Monitoring

The API provides comprehensive metrics:

```bash
# Health check
curl http://localhost:8080/health

# Storage statistics
curl http://localhost:8080/api/v1/storage/info

# Optimization performance
curl http://localhost:8080/api/v1/optimization/stats

# Cache performance
curl http://localhost:8080/api/v1/cache/stats
```

## ğŸ¯ Use Cases

- **VS Code Extensions**: Drop-in context provider for AI coding assistants
- **Local AI Systems**: Ollama, LocalAI, edge deployment context optimization
- **Document Q&A**: Intelligent document retrieval for RAG applications
- **Code Analysis**: Smart code snippet selection for AI code review
- **Research Tools**: Academic paper and document context assembly

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ”¬ Technical Details

For complete implementation details, algorithms, and architecture decisions, see the documentation in the `docs/` directory.

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“ Support

- **Documentation**: See the `docs/` directory for technical details
- **Issues**: Report bugs and feature requests via GitHub Issues
- **Community**: Join the discussions for help and feature requests

---

**ContextLite** - Making AI context assembly fast, local, and intelligent.

---

**ContextLite** - Because context matters, and speed matters more. ğŸš€
